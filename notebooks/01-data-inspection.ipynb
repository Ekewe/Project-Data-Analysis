{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1345a630-d8da-4bed-ade5-8094e17709d9",
   "metadata": {},
   "source": [
    "# Data Inspection: Landmark Complaint Dataset\n",
    "This notebook provides an overview of the dataset, including the structure of the JSON file, exploration of key fields, and a summary of the initial data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aae3f517-0791-47f4-88dc-63c89a0ac8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0221df1c-8b91-4cf8-974a-165cb1456b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level keys in the JSON file: dict_keys(['meta', 'data'])\n",
      "Number of records in the dataset: 2\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Load the JSON file\n",
    "file_path = '../data/raw/rows.json'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Display the top-level keys in the JSON file\n",
    "print(\"Top-level keys in the JSON file:\", data.keys())\n",
    "\n",
    "# If the data is a list of records, check the length\n",
    "print(\"Number of records in the dataset:\", len(data))\n",
    "\n",
    "# Check the data type\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1122fdd5-56e9-4045-bea5-00c3a0550c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['row-csqc_si9s-y3zq', '00000000-0000-0000-C108-4475AF4D25A0', 0, 1713988809, None, 1713988809, None, '{ }', 'CMP-15-00005', '2014-07-01T00:00:00', '903', 'Sterling Place', 'Brooklyn', '1241', '58', '3031568', '11216', 'Crown Heights North  II - Historic District', 'painting base of building without permits', 'Warning Letter Issued', 'Closed', '36', 'BK-8', 'Crown Heights North', '40.67245484480163', '-73.94872661471051'], ['row-pzxe.ii3d_fii8', '00000000-0000-0000-3781-24548438F830', 0, 1713988809, None, 1713988809, None, '{ }', 'CMP-15-00004', '2014-07-01T00:00:00', '93', 'St. Johns Place', 'Brooklyn', '945', '77', '3019314', '11217', 'Park Slope - Historic District', 'work being done; working on building façade', 'No Warning Letter Issued', 'Closed', '39', 'BK-6', 'Park Slope-Gowanus', '40.67720674265087', '-73.97602168537509'], ['row-59y2-accu~8a8t', '00000000-0000-0000-FAC0-DEF910573748', 0, 1713988809, None, 1713988809, None, '{ }', 'CMP-15-00003', '2014-07-01T00:00:00', '131', 'East 65th Street', 'Manhattan', '1400', '113', '1042450', '10065', 'Upper East Side - Historic District', 'Construction of rear yard addition without permits; photographs with complaint file', 'Warning Letter Issued', 'Closed', '04', 'MN-8', 'Upper East Side-Carnegie Hill', '40.76613981857926', '-73.96579132189767'], ['row-z5ub~g3a5~aaxs', '00000000-0000-0000-9C60-F40D758E170B', 0, 1713988809, None, 1713988809, None, '{ }', 'CMP-15-00002', '2014-07-01T00:00:00', '1156', 'Dean Street', 'Brooklyn', '1212', '24', '3030313', '11216', 'Crown Heights North - Historic District', 'Painting front walls', 'Warning Letter Issued', 'Closed', '36', 'BK-8', 'Crown Heights North', '40.67694366645024', '-73.95129007012825'], ['row-73jm_ytbm.n2dq', '00000000-0000-0000-6600-58D99D28488D', 0, 1713988809, None, 1713988809, None, '{ }', 'CMP-15-00001', '2014-07-01T00:00:00', '180', '10th Avenue', 'Manhattan', '718', '7502', '1088996', '10011', 'Chelsea - Historic District', 'Installation of bar on patio', 'No Warning Letter Issued', 'Closed', '03', 'MN-4', 'Hudson Yards-Chelsea-Flatiron-Union Square', '40.746215183444626', '-74.00522937407204']]\n"
     ]
    }
   ],
   "source": [
    "# Convert the dictionary to a list\n",
    "data_items = data['data']\n",
    "\n",
    "# Print the first 5 key-value pairs from the dictionary\n",
    "print(data_items[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4303ae-0631-4fd9-9ade-f9210a5dfe36",
   "metadata": {},
   "source": [
    "From the printed data, we now understand that the dataset is structured as a list of lists, with each sublist containing various details about a complaint. Among this information is the actual complaint description, which we need to extract. Our next step will be to isolate the complaint text from the rest of the data for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f5e4163-930a-48c7-a5e8-d98dfc58cf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complaint 1: painting base of building without permits\n",
      "Complaint 2: work being done; working on building façade\n",
      "Complaint 3: Construction of rear yard addition without permits; photographs with complaint file\n",
      "Complaint 4: Painting front walls\n",
      "Complaint 5: Installation of bar on patio\n"
     ]
    }
   ],
   "source": [
    "# Extracting the complaint text found at index 18\n",
    "complaint_texts = [entry[18] for entry in data_items if len(entry) > 18]\n",
    "\n",
    "# print the first 5 complaints descriptions to verify\n",
    "for i, complaint in enumerate(complaint_texts[:5]):\n",
    "    print(f\"Complaint {i+1}: {complaint}\")\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "complaints_df = pd.DataFrame(complaint_texts, columns=['Complaint Text'])\n",
    "\n",
    "# Save the complaints to a CSV file\n",
    "complaints_df.to_csv('complaints_extracted.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb2db7c-7962-47f1-be93-56e16696b98e",
   "metadata": {},
   "source": [
    "We've successfully extracted and printed the first 5 complaints. Each complaint provides insights into issues reported, such as unauthorized modifications or construction work. This extraction will help us focus solely on the complaint descriptions, allowing us to apply NLP techniques to analyze common themes and topics within the dataset. To facilitate further analysis, we have converted the complaints into a DataFrame and saved them into a CSV file, making it easy to load and process in the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fa1807-204b-4abd-8deb-d57dcf819a68",
   "metadata": {},
   "source": [
    "In this notebook, we loaded and inspected the dataset, identifying it as a list of lists with various fields, including complaint descriptions. We isolated the complaint text, which will be the focus of our NLP analysis.\n",
    "\n",
    "In the next notebook, we will clean and preprocess the complaint texts to prepare them for topic modeling and other NLP tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
